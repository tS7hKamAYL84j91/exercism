{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL\n",
    "\n",
    "We are going to do the `Transform` step of an Extract-Transform-Load.\n",
    "\n",
    "### ETL\n",
    "\n",
    "Extract-Transform-Load (ETL) is a fancy way of saying, \"We have some crufty, legacy data over in this system, and now we need it in this shiny new system over here, so\n",
    "we're going to migrate this.\"\n",
    "\n",
    "(Typically, this is followed by, \"We're only going to need to run this\n",
    "once.\" That's then typically followed by much forehead slapping and\n",
    "moaning about how stupid we could possibly be.)\n",
    "\n",
    "### The goal\n",
    "\n",
    "We're going to extract some scrabble scores from a legacy system.\n",
    "\n",
    "The old system stored a list of letters per score:\n",
    "\n",
    "- 1 point: \"A\", \"E\", \"I\", \"O\", \"U\", \"L\", \"N\", \"R\", \"S\", \"T\",\n",
    "- 2 points: \"D\", \"G\",\n",
    "- 3 points: \"B\", \"C\", \"M\", \"P\",\n",
    "- 4 points: \"F\", \"H\", \"V\", \"W\", \"Y\",\n",
    "- 5 points: \"K\",\n",
    "- 8 points: \"J\", \"X\",\n",
    "- 10 points: \"Q\", \"Z\",\n",
    "\n",
    "The shiny new scrabble system instead stores the score per letter, which\n",
    "makes it much faster and easier to calculate the score for a word. It\n",
    "also stores the letters in lower-case regardless of the case of the\n",
    "input letters:\n",
    "\n",
    "- \"a\" is worth 1 point.\n",
    "- \"b\" is worth 3 points.\n",
    "- \"c\" is worth 3 points.\n",
    "- \"d\" is worth 2 points.\n",
    "- Etc.\n",
    "\n",
    "Your mission, should you choose to accept it, is to transform the legacy data\n",
    "format to the shiny new format.\n",
    "\n",
    "### Notes\n",
    "\n",
    "A final note about scoring, Scrabble is played around the world in a\n",
    "variety of languages, each with its own unique scoring table. For\n",
    "example, an \"E\" is scored at 2 in the MÄori-language version of the\n",
    "game while being scored at 4 in the Hawaiian-language version.\n",
    "## Source\n",
    "\n",
    "The Jumpstart Lab team [http://jumpstartlab.com](http://jumpstartlab.com)\n",
    "\n",
    "\n",
    "## Version compatibility\n",
    "This exercise has been tested on Julia versions >=1.0.\n",
    "\n",
    "## Submitting Incomplete Solutions\n",
    "It's possible to submit an incomplete solution so you can see how others have completed the exercise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transform (generic function with 2 methods)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# submit\n",
    "function transform(input::AbstractArray)\n",
    "    input |> keys |> collect |> ks -> map(k -> Dict( map(lowercase, input[k])  .=> k), ks) |> ks -> reduce(merge, ks)\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[1mTest Summary:   | \u001b[22m\u001b[39m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal\u001b[22m\u001b[39m\n",
      "a single letter | \u001b[32m   1  \u001b[39m\u001b[36m    1\u001b[39m\n",
      "\u001b[37m\u001b[1mTest Summary:                      | \u001b[22m\u001b[39m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal\u001b[22m\u001b[39m\n",
      "single score with multiple letters | \u001b[32m   1  \u001b[39m\u001b[36m    1\u001b[39m\n",
      "\u001b[37m\u001b[1mTest Summary:                         | \u001b[22m\u001b[39m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal\u001b[22m\u001b[39m\n",
      "multiple scores with multiple letters | \u001b[32m   1  \u001b[39m\u001b[36m    1\u001b[39m\n",
      "\u001b[37m\u001b[1mTest Summary:                                     | \u001b[22m\u001b[39m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal\u001b[22m\u001b[39m\n",
      "multiple scores with differing numbers of letters | \u001b[32m   1  \u001b[39m\u001b[36m    1\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Test.DefaultTestSet(\"multiple scores with differing numbers of letters\", Any[], 1, false)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Test\n",
    "\n",
    "# include(\"etl.jl\")\n",
    "\n",
    "@testset \"a single letter\" begin\n",
    "    input = Dict(1=>['A'])\n",
    "    output = Dict('a'=>1)\n",
    "    @test transform(input) == output\n",
    "end\n",
    "\n",
    "@testset \"single score with multiple letters\" begin\n",
    "    input = Dict(1=>['A', 'E', 'I', 'O', 'U'])\n",
    "    output = Dict('a'=>1, 'e'=>1, 'i'=>1, 'o'=>1, 'u'=>1)\n",
    "    @test transform(input) == output\n",
    "end\n",
    "\n",
    "@testset \"multiple scores with multiple letters\" begin\n",
    "    input = Dict(1=>['A', 'E'], 2=>['D', 'G'])\n",
    "    output = Dict('g'=>2, 'e'=>1, 'a'=>1, 'd'=>2)\n",
    "    @test transform(input) == output\n",
    "end\n",
    "\n",
    "@testset \"multiple scores with differing numbers of letters\" begin\n",
    "    input = Dict(1=>[ 'A', 'E', 'I', 'O', 'U', 'L', 'N', 'R', 'S', 'T' ],\n",
    "                 2=>[ 'D', 'G' ], 3=>[ 'B', 'C', 'M', 'P' ],\n",
    "                 4=>[ 'F', 'H', 'V', 'W', 'Y' ], 5=>[ 'K' ],\n",
    "                 8=>[ 'J', 'X' ], 10=>[ 'Q', 'Z' ])\n",
    "    output = Dict('a'=>1, 'b'=>3,  'c'=>3, 'd'=>2, 'e'=>1,\n",
    "                  'f'=>4, 'g'=>2,  'h'=>4, 'i'=>1, 'j'=>8,\n",
    "                  'k'=>5, 'l'=>1,  'm'=>3, 'n'=>1, 'o'=>1,\n",
    "                  'p'=>3, 'q'=>10, 'r'=>1, 's'=>1, 't'=>1,\n",
    "                  'u'=>1, 'v'=>4,  'w'=>4, 'x'=>8, 'y'=>4,\n",
    "                  'z'=>10)\n",
    "    @test transform(input) == output\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To submit your exercise, you need to save your solution in a file called etl.jl before using the CLI.\n",
    "# You can either create it manually or use the following functions, which will automatically\n",
    "# save every notebook cell starting with `# submit` in that file.\n",
    "\n",
    "# Pkg.add(\"Exercism\")\n",
    "using Exercism\n",
    "Exercism.create_submission(\"etl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a': ASCII/Unicode U+0061 (category Ll: Letter, lowercase)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowercase('A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Int64,Array{Char,1}} with 7 entries:\n",
       "  4  => ['F', 'H', 'V', 'W', 'Y']\n",
       "  10 => ['Q', 'Z']\n",
       "  2  => ['D', 'G']\n",
       "  3  => ['B', 'C', 'M', 'P']\n",
       "  5  => ['K']\n",
       "  8  => ['J', 'X']\n",
       "  1  => ['A', 'E', 'I', 'O', 'U', 'L', 'N', 'R', 'S', 'T']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = Dict(1=>[ 'A', 'E', 'I', 'O', 'U', 'L', 'N', 'R', 'S', 'T' ],\n",
    "                 2=>[ 'D', 'G' ], 3=>[ 'B', 'C', 'M', 'P' ],\n",
    "                 4=>[ 'F', 'H', 'V', 'W', 'Y' ], 5=>[ 'K' ],\n",
    "                 8=>[ 'J', 'X' ], 10=>[ 'Q', 'Z' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Char,Int64} with 16 entries:\n",
       "  'f' => 4\n",
       "  'w' => 4\n",
       "  'd' => 2\n",
       "  'h' => 4\n",
       "  'y' => 4\n",
       "  'j' => 8\n",
       "  'k' => 5\n",
       "  'q' => 10\n",
       "  'c' => 3\n",
       "  'p' => 3\n",
       "  'm' => 3\n",
       "  'z' => 10\n",
       "  'v' => 4\n",
       "  'g' => 2\n",
       "  'x' => 8\n",
       "  'b' => 3"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dict(lowercase(l) => k for (k,ls) in input for l in ls if k > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Char,Int64} with 10 entries:\n",
       "  'T' => 1\n",
       "  'U' => 1\n",
       "  'A' => 1\n",
       "  'I' => 1\n",
       "  'L' => 1\n",
       "  'E' => 1\n",
       "  'R' => 1\n",
       "  'S' => 1\n",
       "  'O' => 1\n",
       "  'N' => 1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dict([ 'A', 'E', 'I', 'O', 'U', 'L', 'N', 'R', 'S', 'T' ] .=> 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
